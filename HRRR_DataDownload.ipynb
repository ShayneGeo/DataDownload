{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da6641d5-32fd-4b14-a93e-2fb66ed8a4b6",
   "metadata": {},
   "source": [
    "# Dependencies  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f58089-d31f-4250-a8f3-ec3cde428e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from herbie import Herbie\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import traceback\n",
    "import s3fs\n",
    "import numcodecs as ncd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "import xarray as xr\n",
    "import math\n",
    "from shapely.ops import unary_union\n",
    "from shapely.geometry import Point, LineString\n",
    "import time\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# resources:\n",
    "# https://mesowest.utah.edu/html/hrrr/zarr_documentation/html/ex_python_plot_zarr.html\n",
    "# https://home.chpc.utah.edu/~u0553130/Brian_Blaylock/HRRR_archive/hrrr_sfc_table_f02-f18.html\n",
    "# https://www.nco.ncep.noaa.gov/pmb/products/hrrr/ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f87d4-a18f-4225-8a2c-e3a7a6999218",
   "metadata": {},
   "source": [
    "# Weather data for lat long date hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb343216-afaf-4ba3-9113-c3d8c18bfa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#location:  Can only do coordinates in area that is covered by the HRRR CONUS grid.\n",
    "point_lat = 40.7608\n",
    "point_lon = -113.8910\n",
    "\n",
    "# Date: [YYYYMMDD] must be in this format. Example is for Jan 8, 2021\n",
    "date = '20200917'\n",
    "\n",
    "# Hour: [00-23]z must be in the two digit format  i.e. 06 or 19\n",
    "hr = '00'\n",
    "\n",
    "# Level: \n",
    "level = 'surface'\n",
    "\n",
    "# Variable:\n",
    "var = 'GUST'\n",
    "\n",
    "data_url = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "###\n",
    "###\n",
    "###\n",
    "# This is the projection the HRRR grid uses.\n",
    "projection = ccrs.LambertConformal(central_longitude=262.5, \n",
    "                                   central_latitude=38.5, \n",
    "                                   standard_parallels=(38.5, 38.5),\n",
    "                                    globe=ccrs.Globe(semimajor_axis=6371229,\n",
    "                                                     semiminor_axis=6371229))\n",
    "\n",
    "x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "\n",
    "nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "#print(fcst_chunk_id)\n",
    "\n",
    "#%%time\n",
    "def retrieve_data(s3_url):\n",
    "    with fs.open(s3_url, 'rb') as compressed_data: # using s3fs\n",
    "        buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "\n",
    "        dtype = \"<f2\"\n",
    "        if \"surface/PRES\" in s3_url: \n",
    "            dtype = \"<f4\"\n",
    "\n",
    "        chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "        \n",
    "        entry_size = 150*150\n",
    "        num_entries = len(chunk)//entry_size\n",
    "\n",
    "        if num_entries == 1: # analysis file is 2d\n",
    "            data_array = np.reshape(chunk, (150, 150))\n",
    "        else:\n",
    "            data_array = np.reshape(chunk, (num_entries, 150, 150))\n",
    "\n",
    "    return data_array\n",
    "\n",
    "\n",
    "data = retrieve_data(data_url + fcst_chunk_id)\n",
    "print(data.shape)\n",
    "\n",
    "gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "\n",
    "plt.title('HRRR Zarr Example %s Forecast' %(var))\n",
    "plt.xlabel('Forecast Hour')\n",
    "plt.ylabel(var)\n",
    "plt.plot(gridpoint_forecast)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a9b94-441d-4a87-890b-d3e2a684b173",
   "metadata": {},
   "source": [
    "# Slice to get only the first 24 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab08541d-5225-41b2-b85e-b59ded6346f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_day_forecast = data[:24, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "\n",
    "plt.title(f'HRRR Zarr Example {var} Forecast for {date}')\n",
    "plt.xlabel('Forecast Hour')\n",
    "plt.ylabel(var)\n",
    "plt.plot(one_day_forecast)\n",
    "plt.show()\n",
    "\n",
    "print(one_day_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b77fe8-ff66-4e00-8c98-812700492fc9",
   "metadata": {},
   "source": [
    "# Visual: single date and single variable TMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645b867-5f14-48c7-ad9b-88c827c51339",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = Herbie(\n",
    "    \"2023-07-12\",\n",
    "    model=\"hrrr\",\n",
    "    product=\"sfc\",\n",
    "    fxx=14,\n",
    ")\n",
    "\n",
    "# Show available products\n",
    "print(H.PRODUCTS)\n",
    "\n",
    "ds = H.xarray(\"TMP:2 m above\")\n",
    "\n",
    "#\n",
    "##\n",
    "###\n",
    "####\n",
    "#####\n",
    "#plot\n",
    "fig = plt.figure(figsize=[10, 8])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "ax.add_feature(cfeature.STATES)\n",
    "\n",
    "p = ax.pcolormesh(\n",
    "    ds.longitude,\n",
    "    ds.latitude,\n",
    "    ds.t2m, \n",
    "    transform=ccrs.PlateCarree(),\n",
    "    vmin=266, \n",
    "    vmax=310,\n",
    ")\n",
    "cbar = plt.colorbar(\n",
    "    p,\n",
    "    ax=ax,\n",
    "    orientation=\"horizontal\",\n",
    "    pad=0.01,\n",
    "    shrink=0.8,\n",
    ")\n",
    "\n",
    "#ax.set_extent([-125, -102, 32, 42])\n",
    "\n",
    "ax.set_title(f\"Variable: Temperature - Date: 2023-07-12\")\n",
    "\n",
    "plt.show()\n",
    "######\n",
    "#####\n",
    "####\n",
    "###\n",
    "##\n",
    "#\n",
    "##\n",
    "###\n",
    "####\n",
    "#####\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd4d9d7-9417-43d9-b71e-9456654334c5",
   "metadata": {},
   "source": [
    "# Plot Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef47b4d-2ada-430b-8038-e7978ddcca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable(var_name, date):\n",
    "    H = Herbie(\n",
    "        date,\n",
    "        model=\"hrrr\",\n",
    "        product=\"sfc\",\n",
    "        fxx=14,\n",
    "    )\n",
    "    \n",
    "    # Assuming H is your Herbie object\n",
    "    ds = H.xarray(var_name)\n",
    "\n",
    "    # Extract the first (and presumably only) data variable name\n",
    "    data_var = list(ds.data_vars)[0]\n",
    "\n",
    "    # Fetch the actual data for the variable\n",
    "    data = ds[data_var]\n",
    "\n",
    "    fig = plt.figure(figsize=[10, 8])\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "\n",
    "    p = ax.pcolormesh(\n",
    "        ds.longitude,\n",
    "        ds.latitude,\n",
    "        data, \n",
    "        transform=ccrs.PlateCarree(),\n",
    "        vmin=data.min(), \n",
    "        vmax=data.max(),\n",
    "    )\n",
    "    \n",
    "    cbar = plt.colorbar(\n",
    "        p,\n",
    "        ax=ax,\n",
    "        orientation=\"horizontal\",\n",
    "        pad=0.01,\n",
    "        shrink=0.8,\n",
    "    )\n",
    "    \n",
    "    ax.set_extent([-125, -102, 32, 42])\n",
    "    \n",
    "    #ax.set_title(f\"Variable: {var_name} - Date: {date}\")\n",
    "    fig.text(0.5, 0.12, f\"Variable: {var_name} - Date: {date}\", ha='center')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Example usage: ONLY CHANGE THIS\n",
    "# https://www.nco.ncep.noaa.gov/pmb/products/hrrr/hrrr.t00z.wrfprsf00.grib2.shtml\n",
    "plot_variable(\"RH:2 m above\", \"2023-07-12\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c81ef7-484e-45a0-8ec4-56559330502b",
   "metadata": {},
   "source": [
    "# Prepare data - daily fire progression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7dd530-1981-42d4-8203-dc09d0392fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "# Open the shapefile and create a GeoDataFrame\n",
    "gdf = gpd.read_file(\"C:\\\\PATH\\\\TO\\\\FILE\\\\Dixie_DailyFireProg_VIIRS.shp\")\n",
    "\n",
    "# Convert the timestamp column to datetime type\n",
    "gdf['t'] = pd.to_datetime(gdf['t'])\n",
    "\n",
    "# Group the GeoDataFrame by 't' and 'FireName' and apply unary_union to combine the polygons\n",
    "grouped = gdf.groupby(['t', 'fireid'])\n",
    "\n",
    "# Create a new GeoDataFrame with the combined polygons and additional attributes\n",
    "gdf_combined = grouped.agg({'geometry': unary_union, 'farea': 'first'}).reset_index()\n",
    "\n",
    "# Create a GeoDataFrame from the combined polygons\n",
    "gdf_combined = gpd.GeoDataFrame(gdf_combined, geometry='geometry')\n",
    "\n",
    "# Sort the GeoDataFrame by the timestamp\n",
    "gdf_sorted = gdf_combined.sort_values('t')\n",
    "\n",
    "# Select rows with a timestamp of 12:00:00\n",
    "gdf_1200 = gdf_sorted[gdf_sorted['t'].dt.time == datetime.time(0, 0, 0)]\n",
    "\n",
    "# Calculate the change in \"farea\" for each FireName\n",
    "gdf_1200['farea_change'] = gdf_1200.groupby('fireid')['farea'].diff()\n",
    "\n",
    "gdf_1200['farea_change'] = gdf_1200['farea_change'].clip(lower=0)\n",
    "\n",
    "# Set values of 'farea_change' to zero if they are less than 50 acre change\n",
    "#gdf_1200.loc[gdf_1200['farea_change'] < 0.005, 'farea_change'] = 0\n",
    "\n",
    "# Replace NaN values in \"farea_change\" with 0\n",
    "gdf_1200['farea_change'] = gdf_1200['farea_change'].fillna(0)\n",
    "\n",
    "gdf_1200_pt = gdf_1200.copy()\n",
    "\n",
    "gdf_1200_pt['geometry'] = gdf_1200_pt['geometry'].centroid\n",
    "\n",
    "gdf_1200_pt = gpd.GeoDataFrame(gdf_1200_pt, geometry='geometry')\n",
    "\n",
    "gdf_1200_pt['Latitude'] = gdf_1200_pt['geometry'].y\n",
    "\n",
    "gdf_1200_pt['Longitude'] = gdf_1200_pt['geometry'].x\n",
    "\n",
    "gdf_1200_pt['farea_change_shifted'] = gdf_1200_pt.groupby('fireid')['farea_change'].shift(-1)\n",
    "\n",
    "gdf_1200_pt['farea_change_shifted'] = gdf_1200_pt['farea_change_shifted'].fillna(0)\n",
    "\n",
    "columns_to_join = ['fireid', 't', 'n_pixels','n_newpixel','meanfrp','fperim','duration']\n",
    "\n",
    "gdf_1200_pt = pd.merge(gdf_1200_pt, gdf[columns_to_join], on=['fireid', 't'], how='left')\n",
    "\n",
    "# Convert the timestamp column to datetime type\n",
    "gdf_1200_pt['t'] = pd.to_datetime(gdf_1200_pt['t'])\n",
    "\n",
    "FireNameList = gdf_1200_pt[\"fireid\"].unique()\n",
    "print(FireNameList)\n",
    "\n",
    "gdf_1200_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c471818c-d5f6-4162-92c5-5076de475cbd",
   "metadata": {},
   "source": [
    "# Download - hrrrzarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9d4faf-027f-4583-bbe3-ad5509da8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://home.chpc.utah.edu/~u0553130/Brian_Blaylock/HRRR_archive/hrrr_prs_table_f00-f01.html\n",
    "\n",
    "# #FireNameList = gdf_1200_pt[\"FireName\"].unique()\n",
    "# FireNameList = [\"AUGUST COMPLEX\",\"RED SALMON COMPLEX\",\"OAK\",\"ABNEY\",\"CAMERON PEAK\",\"EAST TROUBLESOME\",\"MULLEN\",\n",
    "#                 \"MCLEOD\", \"CRESCENT MOUNTAIN\", \"CARR\",\"FERGUSON\",\"WATSON CREEK\",\n",
    "#                \"CHETCO BAR\",\"BALD MOUNTAIN\",\"DOLLAR RIDGE\",\"COUGAR CREEK\",\"TAYLOR CREEK\",\"MILES\",\n",
    "#                \"CAMP\",\"WALKER\",\"DECKER\",\"CREEK\",\"CASTLE\",\"EAST FORK\",\"BUSH\",\"BIGHORN\",\n",
    "#                \"CEDAR CREEK\", \"COW CANYON\",\"BEAR\"]\n",
    "\n",
    "# ~~~change 'output_file' below to export csv for each fire~~~ \n",
    "\n",
    "# Hour: [00-23]z must be in the two digit format  i.e. 06 or 19\n",
    "# noon\n",
    "hr = '12'\n",
    "\n",
    "for i in range(len(FireNameList)):\n",
    "    \n",
    "    try:\n",
    "        selected_fire = FireNameList[i]\n",
    "        gdf_singleFire = gdf_1200_pt[gdf_1200_pt[\"fireid\"] == selected_fire]\n",
    "\n",
    "        LatitudeLIST = gdf_singleFire['Latitude'].tolist()\n",
    "        LongitudeLIST = gdf_singleFire[\"Longitude\"].tolist()\n",
    "        DateLIST = gdf_singleFire[\"t\"].tolist()\n",
    "        print(f\"The number of days: {len(LatitudeLIST)}\")\n",
    "\n",
    "        #\n",
    "        ##\n",
    "        ###\n",
    "        ####\n",
    "        for i in range(len(gdf_singleFire)):\n",
    "\n",
    "            # point_lat = 40.7608\n",
    "            # point_lon = -113.8910\n",
    "\n",
    "            # # Date: [YYYYMMDD] must be in this format\n",
    "            # date = '20230718'\n",
    "\n",
    "            #location: Example is Salt Lake City (SLC). Can only do coordinates in area that is covered by the HRRR CONUS grid.\n",
    "            point_lat = LatitudeLIST[i]\n",
    "            point_lon = LongitudeLIST[i]\n",
    "            date_string = DateLIST[i]\n",
    "\n",
    "            from datetime import datetime\n",
    "            from dateutil.relativedelta import relativedelta\n",
    "\n",
    "            date_object = datetime.strptime(date_string.strftime('%Y-%m-%d'), \"%Y-%m-%d\")\n",
    "            date = date_object.strftime(\"%Y%m%d\")#+ relativedelta(years=4)\n",
    "\n",
    "            # Date: [YYYYMMDD] must be in this format. Example is for Jan 8, 2021\n",
    "            #date = '20180713'\n",
    "            print(type(date))\n",
    "            print(date)\n",
    "\n",
    "            # Temperature (K)\n",
    "            level = 'surface'\n",
    "            var = 'TMP'\n",
    "            data_TMP = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            \n",
    "            # Wind Speed (gust) (m/s)\n",
    "            level = 'surface'\n",
    "            var = 'GUST'\n",
    "            data_GUST = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Surface Roughness (m)\n",
    "            level = 'surface'\n",
    "            var = 'SFCR'\n",
    "            data_SFCR = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Ground Heat Flux (W/m^2)\n",
    "            level = 'surface'\n",
    "            var = 'GFLUX'\n",
    "            data_GFLUX = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Plant Canopy Surface Water (kg/m^2)\n",
    "            level = 'surface'\n",
    "            var = 'CNWAT'\n",
    "            data_CNWAT = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Frictional Velocity (m/s)\n",
    "            level = 'surface'\n",
    "            var = 'FRICV'\n",
    "            data_FRICV = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "    \n",
    "            # Relative Humidity (%)\n",
    "            level = '2m_above_ground'\n",
    "            var = 'RH'\n",
    "            data_RH = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Dew Point Temperature (K)\n",
    "            level = '2m_above_ground'\n",
    "            var = 'DPT'\n",
    "            data_DPT = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            # Specific Humidity (kg/kg)\n",
    "            level = '2m_above_ground'\n",
    "            var = 'SPFH'\n",
    "            data_SPFH = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "          \n",
    "            # Potential Temperature (K)\n",
    "            level = '2m_above_ground'\n",
    "            var = 'POT'\n",
    "            data_POT = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            \n",
    "            # U-Component of Wind (m/s)\n",
    "            level = '10m_above_ground'\n",
    "            var = 'UGRD'\n",
    "            data_UGRD = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "       \n",
    "            # V-Component of Wind (m/s)\n",
    "            level = '10m_above_ground'\n",
    "            var = 'VGRD'\n",
    "            data_VGRD = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "            \n",
    "            # Vegetation Type (Integer(0-13))\n",
    "            level = 'surface'\n",
    "            var = 'VGTYP'\n",
    "            data_VGTYP = f'hrrrzarr/sfc/{date}/{date}_{hr}z_fcst.zarr/{level}/{var}/{level}/{var}/'\n",
    "\n",
    "            fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "            chunk_index = xr.open_zarr(s3fs.S3Map(\"s3://hrrrzarr/grid/HRRR_chunk_index.zarr\", s3=fs))\n",
    "            ###\n",
    "            ###\n",
    "            ###\n",
    "            import cartopy.crs as ccrs\n",
    "\n",
    "            # This is the projection the HRRR grid uses.\n",
    "            projection = ccrs.LambertConformal(central_longitude=262.5, \n",
    "                                               central_latitude=38.5, \n",
    "                                               standard_parallels=(38.5, 38.5),\n",
    "                                                globe=ccrs.Globe(semimajor_axis=6371229,\n",
    "                                                                 semiminor_axis=6371229))\n",
    "\n",
    "            x, y = projection.transform_point(point_lon, point_lat, ccrs.PlateCarree())\n",
    "\n",
    "            nearest_point = chunk_index.sel(x=x, y=y, method=\"nearest\")\n",
    "            fcst_chunk_id = f\"0.{nearest_point.chunk_id.values}\"\n",
    "            #print(fcst_chunk_id)\n",
    "            ###\n",
    "            ###\n",
    "            ###\n",
    "\n",
    "            #%%time\n",
    "            def retrieve_data(s3_url):\n",
    "                with fs.open(s3_url, 'rb') as compressed_data: # using s3fs\n",
    "                    buffer = ncd.blosc.decompress(compressed_data.read())\n",
    "\n",
    "                    dtype = \"<f2\"\n",
    "                    if \"surface/PRES\" in s3_url: # surface/PRES is the only variable with a larger data type\n",
    "                        dtype = \"<f4\"\n",
    "\n",
    "                    chunk = np.frombuffer(buffer, dtype=dtype)\n",
    "\n",
    "                    entry_size = 150*150\n",
    "                    num_entries = len(chunk)//entry_size\n",
    "\n",
    "                    if num_entries == 1: # analysis file is 2d\n",
    "                        data_array = np.reshape(chunk, (150, 150))\n",
    "                    else:\n",
    "                        data_array = np.reshape(chunk, (num_entries, 150, 150))\n",
    "\n",
    "                return data_array\n",
    "            \n",
    "            try:\n",
    "                data = retrieve_data(data_TMP + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'TMP'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'TMP'] = \"NOTAVAILABLE\"\n",
    "\n",
    "            try:\n",
    "                data = retrieve_data(data_GUST + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'GUST'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'GUST'] = \"NOTAVAILABLE\"\n",
    "            \n",
    "            try:\n",
    "                data = retrieve_data(data_SFCR + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'SFCR'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'SFCR'] = \"NOTAVAILABLE\"\n",
    "                \n",
    "            try:\n",
    "                data = retrieve_data(data_GFLUX + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'GFLUX'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'GFLUX'] = \"NOTAVAILABLE\"\n",
    "\n",
    "            try:                \n",
    "                data = retrieve_data(data_CNWAT + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'CNWAT'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'CNWAT'] = \"NOTAVAILABLE\"\n",
    "                \n",
    "            try:\n",
    "                data = retrieve_data(data_FRICV + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'FRICV'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'FRICV'] = \"NOTAVAILABLE\"\n",
    "\n",
    "            try:\n",
    "                data = retrieve_data(data_RH + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'RH'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'RH'] = \"NOTAVAILABLE\"\n",
    "\n",
    "            try:\n",
    "                data = retrieve_data(data_DPT + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'DPT'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'DPT'] = \"NOTAVAILABLE\"\n",
    "                \n",
    "            try:     \n",
    "                data = retrieve_data(data_SPFH + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'SPFH'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'SPFH'] = \"NOTAVAILABLE\"\n",
    "               \n",
    "            try:   \n",
    "                data = retrieve_data(data_POT + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'POT'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'POT'] = \"NOTAVAILABLE\"                \n",
    "                \n",
    "            try:\n",
    "                data = retrieve_data(data_UGRD + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'UGRD'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'UGRD'] = \"NOTAVAILABLE\"                \n",
    "\n",
    "            try:    \n",
    "                data = retrieve_data(data_VGRD + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'VGRD'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'VGRD'] = \"NOTAVAILABLE\"                \n",
    "\n",
    "            try:    \n",
    "                data = retrieve_data(data_VGTYP + fcst_chunk_id)\n",
    "                gridpoint_forecast = data[:, nearest_point.in_chunk_y, nearest_point.in_chunk_x]\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'VGTYP'] = gridpoint_forecast[0]\n",
    "            except:\n",
    "                gdf_singleFire.at[gdf_singleFire.index[i], 'VGTYP'] = \"NOTAVAILABLE\"                \n",
    "                  \n",
    "            print(i)\n",
    "\n",
    "        # Define the output file path and name\n",
    "        output_file = f\"C:\\\\PATH\\\\TO\\\\OUTPUT\\\\FILE\\\\HRRR_{selected_fire}.csv\"\n",
    "    \n",
    "        # Save the GeoDataFrame as a CSV file\n",
    "        gdf_singleFire.to_csv(output_file, index=False)\n",
    "        ####\n",
    "        ###\n",
    "        ##\n",
    "        #\n",
    "    except Exception as e:\n",
    "        \n",
    "        print(f\"An error occurred for {selected_fire}:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        continue\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c25169c-d7f6-49da-8c2f-3da3f051b53b",
   "metadata": {},
   "source": [
    "# GIF of gust "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccba82c0-b419-4f5d-926b-4f1b7f4d55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "from datetime import timedelta, datetime\n",
    "\n",
    "# Define start and end dates\n",
    "start_date = datetime(2023, 8, 1)\n",
    "end_date = datetime(2023, 8, 7)\n",
    "\n",
    "# Define a function to update the plot for a given day\n",
    "def update(day):\n",
    "    ax.clear()\n",
    "    ax.add_feature(cfeature.STATES)\n",
    "    date = start_date + timedelta(days=day)\n",
    "    H = Herbie(\n",
    "        date.strftime(\"%Y-%m-%d\"),\n",
    "        model=\"hrrr\",\n",
    "        product=\"sfc\",\n",
    "        fxx=0,\n",
    "    )\n",
    "    #ds = H.xarray(\"TMP:2 m above\")\n",
    "    ds = H.xarray(\"GUST:surface\")\n",
    "    p = ax.pcolormesh(\n",
    "        ds.longitude,\n",
    "        ds.latitude,\n",
    "        ds.gust, \n",
    "        transform=ccrs.PlateCarree(),\n",
    "        vmin=0, \n",
    "        vmax=20,\n",
    "    )\n",
    "    ax.set_extent([-125, -102, 32, 42])\n",
    "    return p,\n",
    "\n",
    "# Create a new figure\n",
    "fig = plt.figure(figsize=[8, 5])\n",
    "ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree())\n",
    "\n",
    "# Create an animation\n",
    "ani = animation.FuncAnimation(fig, update, frames=(end_date-start_date).days, interval=200)\n",
    "\n",
    "# Save the animation as a GIF\n",
    "ani.save('C:\\\\PATH\\\\TO\\\\OUTPUT\\\\WEATHER_GIF.gif', writer='imagemagick')\n",
    "\n",
    "# Close the figure\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d7e22-ac77-4268-963c-495db5e20a48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
