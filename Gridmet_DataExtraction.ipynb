{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80f5dbd-63e0-4e82-a690-89f6ca52c4dc",
   "metadata": {},
   "source": [
    "# Read in shapefile "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe756fe-9ee0-4916-90c4-cb09836ab3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# Read in the shapefile\n",
    "gdf = gpd.read_file(\"C:\\\\PATH\\\\TO\\\\SHAPEFILE\\\\SHAPEFILE.shp\")\n",
    "\n",
    "# Convert the timestamp column to datetime type (change 't' to your own time column name)\n",
    "gdf['t'] = pd.to_datetime(gdf['t'])\n",
    "\n",
    "# select just 2019 data ## out if you want to download the entire dataset\n",
    "gdf = gdf[gdf['t'].dt.year == 2019]\n",
    "\n",
    "# Take only the first 10 rows (comment this out when you know the code is working)\n",
    "gdf = gdf.head(10)\n",
    "\n",
    "print(\"done\")\n",
    "print(len(gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5796a-0c30-4866-aa1b-4e154108511b",
   "metadata": {},
   "source": [
    "## Identify the Lat Long and time columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d1ed84-a82b-4f76-aeea-830d9072b239",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e612c3-355f-40a1-a044-4ba4ca24181f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change 't' to time column in your dataset\n",
    "timecolumn = 't'\n",
    "\n",
    "# change geometry of polygon to the centroid \n",
    "# you can identify \n",
    "gdf['geometry'] = gdf['geometry'].centroid\n",
    "gdf = gpd.GeoDataFrame(gdf, geometry='geometry')\n",
    "\n",
    "gdf['Latitude'] = gdf['geometry'].y\n",
    "gdf['Longitude'] = gdf['geometry'].x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723e2328-b454-4880-8edf-30a8c58b389a",
   "metadata": {},
   "source": [
    "## Downlaod data from http://thredds.northwestknowledge.net/\n",
    "### see variables below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9d5a66-e919-484e-b61b-b445e29a59da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "url = [\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_pr_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_rmax_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_rmin_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_sph_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_srad_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_th_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmn_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_tmmx_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_vs_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_bi_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_fm100_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_fm1000_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_erc_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_pdsi_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_vpd_1979_CurrentYear_CONUS.nc\",\n",
    "\"http://thredds.northwestknowledge.net:8080/thredds/ncss/agg_met_z_1979_CurrentYear_CONUS.nc\"]\n",
    "\n",
    "\n",
    "VariableList = [\n",
    "    'precipitation_amount',\n",
    "    'daily_maximum_relative_humidity',\n",
    "    'daily_minimum_relative_humidity',\n",
    "    'daily_mean_specific_humidity',\n",
    "    'daily_mean_shortwave_radiation_at_surface',\n",
    "    'daily_mean_wind_direction',\n",
    "    'daily_minimum_temperature', \n",
    "    'daily_maximum_temperature', \n",
    "    'daily_mean_wind_speed',\n",
    "    'daily_mean_burning_index_g',\n",
    "    'dead_fuel_moisture_100hr',\n",
    "    'dead_fuel_moisture_1000hr',\n",
    "    'daily_mean_energy_release_component-g',\n",
    "    'daily_mean_palmer_drought_severity_index', \n",
    "    'daily_mean_vapor_pressure_deficit',\n",
    "    'daily_mean_palmer_z_index'\n",
    "]\n",
    "\n",
    "\n",
    "for variable, current_url in zip(VariableList, url):\n",
    "    climate_values = []  # List to store extracted values for the current variable\n",
    "\n",
    "    # Loop through the dataframe rows\n",
    "    for idx, row in gdf.iterrows():\n",
    "        # Extract the latitude, longitude, and date for the current row\n",
    "        latitude = row[\"Latitude\"]\n",
    "        longitude = row[\"Longitude\"]\n",
    "        start_date = pd.to_datetime(row[timecolumn])\n",
    "\n",
    "        # Set the request parameters\n",
    "        params = {\n",
    "            \"var\": variable,\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"time\": start_date.strftime('%Y-%m-%dT%H:%M:%SZ'),\n",
    "            \"addLatLon\": \"true\",\n",
    "            \"accept\": \"netcdf\"\n",
    "        }\n",
    "\n",
    "        # Send the request\n",
    "        response = requests.get(current_url, params=params, timeout=10)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            # If request is successful, save the data to a temporary netCDF file\n",
    "            filename = f\"temp_data_{variable}.nc\"\n",
    "            with open(filename, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "\n",
    "            # Load the netCDF data using xarray\n",
    "            ds = xr.open_dataset(filename)\n",
    "\n",
    "            # Extract the value and append to the list\n",
    "            value_at_point = ds[variable].values[0]\n",
    "            climate_values.append(value_at_point)\n",
    "        else:\n",
    "            print(f\"Failed to retrieve data for index {idx} using variable {variable}. Status code:\", response.status_code)\n",
    "            climate_values.append(None)\n",
    "\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(idx + 1)\n",
    "            print(variable)\n",
    "\n",
    "    # Append the climate_values list as a new column to gdf\n",
    "    gdf[variable] = climate_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdcf3e0-5f3d-4a81-be23-7e3105f65263",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
