{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06085dd-d517-4247-a6cd-5ea1aa75fdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified using code from Matthew Whitley\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3b90eb-6fa4-4465-91be-45b83431298b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_links(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    return links\n",
    "\n",
    "def get_all_files(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    links = soup.find_all('a')\n",
    "    out = []\n",
    "    for link in links[5:]:\n",
    "        href = link.get('href')\n",
    "        subdir_url = url + href\n",
    "        # print(subdir_url)\n",
    "        if subdir_url.endswith('/'):  # Check if the link is a directory\n",
    "            out.append(get_all_files(subdir_url))\n",
    "        else: # if not add download link to outlist\n",
    "            # print('appended')\n",
    "            out.append(subdir_url)  \n",
    "    return out\n",
    "\n",
    "def flatten_list(lst):\n",
    "    flattened = []\n",
    "    for item in lst:\n",
    "        if isinstance(item, list):\n",
    "            flattened.extend(flatten_list(item))\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "    return flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0d3217-8d76-4b7e-98e0-6ea289308a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ftp.wildfire.gov/public/incident_specific_data/calif_s/'\n",
    "region = 'calif_s'\n",
    "fyeardirs = ['2020_Incidents/']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2411f1-14ad-40e5-aa88-656247065e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all the links on the page\n",
    "allout = []\n",
    "links = get_links(url)\n",
    "for link in links[5:]:\n",
    "    href = link.get('href')\n",
    "    print(href)\n",
    "    if href not in fyeardirs:\n",
    "        continue\n",
    "    subdir_url = url + href\n",
    "    sublinks = get_links(subdir_url)\n",
    "    for sl in sublinks[5:]:\n",
    "        href = sl.get('href')\n",
    "        su = subdir_url+href\n",
    "        # force IR dir\n",
    "        irdir = su+'IR/' # THIS IS NOT CONSISTENT AMONG REGIONS AND ACROSS YEARS (so please check it) \n",
    "        # print(irdir)\n",
    "        allout.append(get_all_files(irdir))\n",
    "allout = flatten_list(allout)\n",
    "print(len(allout))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e969743-eae9-4115-a9c9-2b669d169482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# List of URLs to download\n",
    "urls = allout\n",
    "\n",
    "# Directory to save the downloaded files\n",
    "local_directory = 'C:\\\\Users\\\\Desktop\\\\NIROPS_Data'\n",
    "\n",
    "# Function to download a file from a URL\n",
    "def download_file(url):\n",
    "    local_filename = url.split('/')[-1]  # Extract filename from URL\n",
    "    path = os.path.join(local_directory, local_filename)\n",
    "    response = requests.get(url, stream=True)\n",
    "    total_size_in_bytes = int(response.headers.get('content-length', 0))\n",
    "    block_size = 1024 # 1 Kibibyte\n",
    "    with open(path, 'wb') as file, tqdm(\n",
    "        total=total_size_in_bytes, unit='iB', unit_scale=True, desc=local_filename) as progress_bar:\n",
    "        for data in response.iter_content(block_size):\n",
    "            progress_bar.update(len(data))\n",
    "            file.write(data)\n",
    "\n",
    "# Using ThreadPoolExecutor to download files concurrently\n",
    "def download_files(urls):\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        executor.map(download_file, urls)\n",
    "\n",
    "# Download all files concurrently\n",
    "download_files(urls)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
